{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Food Review Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this single notebook, I download a dataset from [Kaggle](https://www.kaggle.com/), prepare the data for a neural network, then train a character-based LSTM model to distinguish between 5-star and 1-star reviews. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I import the libraries that I need:\n",
    "- PyTorch for tensors, tensor functions, and Modules\n",
    "- Pandas for dataframes to hold my dataset\n",
    "- random for shuffling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.functional import F\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I set the random seeds for Python and PyTorch so other people can get the same results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other source of randomness is when I use the `sample` method on DataFrames to shuffle them, but this random seed will be set during each method call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be using the dataset [Amazon Fine Food Reviews](https://www.kaggle.com/snap/amazon-fine-food-reviews). To download with the kaggle api, I had to first install the command line tool and follow the relevant instructions [here](https://www.kaggle.com/docs/api). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -d snap/amazon-fine-food-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zipfile.ZipFile('amazon-fine-food-reviews.zip').extractall('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I only want the review text and the scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Text', 'Score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also create a new column that shows the length of each review text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Length'] = df['Text'].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I remove any reviews longer than 500 characters so that training won't take too long, and because the sentiment of the review can probably be determined within the first 500 characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Length'] <= 500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to see how many of each review score I have in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36599</td>\n",
       "      <td>36599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19853</td>\n",
       "      <td>19853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27125</td>\n",
       "      <td>27125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53400</td>\n",
       "      <td>53400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>277850</td>\n",
       "      <td>277850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Text  Length\n",
       "Score                \n",
       "1       36599   36599\n",
       "2       19853   19853\n",
       "3       27125   27125\n",
       "4       53400   53400\n",
       "5      277850  277850"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Score').agg('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there are enough 1-star and 5-star reviews for me to just train with those (making this a binary classification task):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1s = df[df['Score']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5s = df[df['Score']==5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want the data to be balanced (the same number of items in each category), which it isn't at the moment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36599, 277850)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_1s), len(df_5s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I randomly pick a subset of the 5-star reviews that is the same size as my collection of 1-star reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5s = df_5s.sample(len(df_1s), random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And I check that they are now the same size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36599, 36599)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_1s), len(df_5s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review text length analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to see a histogram of the lengths of all the review texts in both of the categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_1s['Length'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_5s['Length'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And I can also look at the average review lengths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264.7288723735621, 242.80302740512036)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1s['Length'].mean(), df_5s['Length'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average actually isn't that important, though. The important takeaway is that there are many reviews of many different lengths. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I group reviews together in batches and pad them to be the same sequence length, I will need to consider how to batch them together in a way that doesn't cause too much unnecessary padding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final dataset and splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I create the final dataset for my project by combining the 1-star and 5-star reviews into a single DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.concat([df_1s, df_5s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73198"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to split the dataset into training and validation sets. I do this by taking the first 80% of the items, and create the variable `cut` to mark the split point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58558"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut = int(.8*len(df_full))\n",
    "cut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I need to shuffle the full set though, so I get a mix of both categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_full.sample(frac=1, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I split the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_full[:cut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df_full[cut:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And check that the size of each looks right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58558, 14640)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train), len(df_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also want to make sure the classes are still balanced within each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29205</td>\n",
       "      <td>29205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29353</td>\n",
       "      <td>29353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Text  Length\n",
       "Score               \n",
       "1      29205   29205\n",
       "5      29353   29353"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby('Score').agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7394</td>\n",
       "      <td>7394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7246</td>\n",
       "      <td>7246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Text  Length\n",
       "Score              \n",
       "1      7394    7394\n",
       "5      7246    7246"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.groupby('Score').agg('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling batches with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll use character-based tokenization, so I don't need to create a vocabulary of words, but instead a vocab of characters. The first step is to get a single string containing all of the review texts combined from the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulltext = df_train['Text'].str.cat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I'll use a `Counter` object to get all the unique characters in the full text and their counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_ctr = Counter(fulltext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the size of the vocab (not including unknown and padding):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tok_ctr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the final vocab list, I add the unknown and padding characters to the front:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocab = ['unk', 'pad'] + [tok for tok,count in tok_ctr.most_common()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`unk` is used for any characters that show up in the validation set which didn't show up in the training set. `pad` is used for adding to the end of some tensors to make them the same size as longer ones, so they stack together evenly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I create two dictionaries for both directions of translating between numbers and character tokens. This is my implementation of numericalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok2num = {tok:num for num,tok in enumerate(vocab)}\n",
    "num2tok = {num:tok for num,tok in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also have a method to translate a whole string to a tensor of numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(s):\n",
    "    return torch.tensor([tok2num[c] if c in tok2num.keys() else 0 for c in s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what happens when it encounters a unicode character that it doesn't have in the vocab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 22, 15,  0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_text('abcÝ­')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It uses 0 instead (the `unk` vocab position) to show that this character is unknown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoding for the score label (which I call `tag`) is easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 5]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_vocab = [1,5]\n",
    "tag_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only two possibilities, which these dictionaries handle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2num = {tag:num for num,tag in enumerate(tag_vocab)}\n",
    "num2tag = {num:tag for num,tag in enumerate(tag_vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({1: 0, 5: 1}, {0: 1, 1: 5})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2num, num2tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most complicated section of the notebook. I need to find a way to batch items somewhat randomly while also batching items of somewhat similar lengths (so that there isn't too much padding on any of the tensors)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is choosing a batch size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is somewhat arbitrary, but also based on what I found worked best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if I wanted the least amount of total padding possible, I could sort the whole dataset from shortest to longest review. Then I would split the whole thing into batches and have very similar length reviews in each batch. Most batches might even have all the reviews be the same length, requiring no padding at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if I did it this completely sorted way, I would always get the same batches of reviews. I could shuffle the order of the batches, but each batch would have the same contents as the last time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My solution is to create buckets of batches. Each bucket is big enough to create many different combination of batches each epoch, but small enough to have similar-length reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_sz = bs * 20 # each bucket can hold 20 batches\n",
    "bucket_sz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is the method for creating batches. It keeps the batches in the form of many DataFrames for now, but they will later be converted to tensors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I sort the items based on length. Then there is an outer loop and an inner loop. The outer loop split the whole dataset into buckets. Then for each created bucket, I shuffle it and do the inner loop, which creates many batches from the bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create batches in DataFrame form\n",
    "def get_dfbs(dset, bucket_sz, bs):\n",
    "    dset = dset.sort_values('Length')\n",
    "    batches = []\n",
    "    for i in range(0,len(dset),bucket_sz):\n",
    "        start = i\n",
    "        end = i+bucket_sz\n",
    "        if end > len(dset):\n",
    "            end = len(dset)\n",
    "        bucket = dset[start:end]\n",
    "        bucket = bucket.sample(frac=1, random_state=0)\n",
    "        for j in range(0,len(bucket), bs):\n",
    "            start = j\n",
    "            end = j+bs\n",
    "            if end > len(bucket):\n",
    "                end = len(bucket)\n",
    "            batch = bucket[start:end]\n",
    "            batches.append(batch)\n",
    "    random.shuffle(batches)\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then make a function to pad tensors to a given length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad a tensor to a certain size, with 1s\n",
    "def pad_to(t, sz):\n",
    "    padded = torch.ones(sz)\n",
    "    padded[:len(t)] = t\n",
    "    return padded.long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then using this padding function, I make a function that creates single tensors from each DataFrame batch. It uses the length of the longest tensor in each batch to determine padding size for the smaller tensors of that batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a dataframe batch to a tensor batch\n",
    "def dfb2tens(dfb):\n",
    "    # x batch\n",
    "    xb = dfb['Text']\n",
    "    pad_sz = dfb['Length'].max()\n",
    "    xb = [encode_text(s) for s in xb]\n",
    "    xb = torch.stack([pad_to(t, pad_sz) for t in xb])\n",
    "    # y batch\n",
    "    yb = dfb['Score']\n",
    "    yb = yb.apply(lambda x: torch.tensor(tag2num[x]))\n",
    "    yb = torch.stack(yb.tolist())\n",
    "    \n",
    "    return xb, yb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I combine all of these in a generator that yields many batches ready for training in a neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a new set of batches for training an epoch\n",
    "def get_batches(dset, bucket_sz, bs):\n",
    "    for dfb in get_dfbs(dset, bucket_sz, bs):\n",
    "        xb, yb = dfb2tens(dfb)\n",
    "        yield xb, yb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My custom model for character-based classification uses embedding, just like word-based models, because it is probably useful to have an embedding space of the around 100 characters in the dataset. This will allow, for example, lowercase letters and their uppercase counterparts to have similar vector representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also return the full sequence of outputs instead of just the final one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoodsModel(nn.Module):\n",
    "    def __init__(self, vocab_sz, emb_sz, hid_sz):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_sz, emb_sz)\n",
    "        self.lstm = nn.LSTM(emb_sz, hid_sz, 1, batch_first=True)\n",
    "        self.lin = nn.Linear(hid_sz, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.emb(x)\n",
    "        out,_ = self.lstm(out)\n",
    "        out = self.lin(out)\n",
    "        return out # return all sequence outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the sizes that worked best during experimentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_sz = 50\n",
    "hid_sz = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And lastly I create the model instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FoodsModel(len(vocab), emb_sz, hid_sz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My custom loss function uses binary cross-entropy, but first pools all the sequence outputs by averaging them together. This worked much better for me, probably because a lot of the information in a long review gets lost by the final step and there is valuable information in all the output steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foods_loss(preds, targs):\n",
    "    preds = preds.squeeze(dim=-1).mean(dim=-1) # pool all outputs into an average score\n",
    "    targs = targs.float()\n",
    "    return F.binary_cross_entropy_with_logits(preds, targs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an optimizer, I just used Adam, since it has always worked well for me:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My accuracy function also needs to pool the outputs first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, targ):\n",
    "    preds = preds.squeeze(dim=-1).mean(dim=-1) # pool all outputs into an average score\n",
    "    return ((preds > 0).float() == targ.float()).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I create a very simple training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_epoch():\n",
    "    for xb, yb in get_batches(df_train, bucket_sz, bs):\n",
    "        preds = model(xb)\n",
    "        loss = foods_loss(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation loop is also simple. It returns average loss and accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_epoch():\n",
    "    losses = []\n",
    "    accs = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in get_batches(df_val, bucket_sz, bs):\n",
    "            preds = model(xb)\n",
    "            loss = foods_loss(preds, yb).item()\n",
    "            losses.append(loss)\n",
    "            acc = accuracy(preds, yb)\n",
    "            accs.append(acc)\n",
    "    avg_loss = torch.tensor(losses).mean().item()\n",
    "    avg_acc = torch.tensor(accs).mean().item()\n",
    "    return avg_loss, avg_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I train the model one epoch at a time, looking at the validation metrics along the way:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3891304135322571, 0.8272379636764526)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss, val_acc = val_epoch()\n",
    "val_loss, val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2880418300628662, 0.8831877708435059)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss, val_acc = val_epoch()\n",
    "val_loss, val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.24672091007232666, 0.9032022953033447)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss, val_acc = val_epoch()\n",
    "val_loss, val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.22392262518405914, 0.9140738844871521)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss, val_acc = val_epoch()\n",
    "val_loss, val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I could keep training, but that took a while and 91% is pretty good accuracy for the purposes of this project. It shows that the model is continuing to improve after each epoch and has learned how to distinguish 1-star and 5-star reviews effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I make a function to predict the score of a single review by feeding in the review text. It also returns the full sequence of outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    tens = encode_text(text)\n",
    "    tens = tens.unsqueeze(dim=0) # create batch of 1\n",
    "    with torch.no_grad():\n",
    "        out = model(tens).squeeze()\n",
    "    pred = out.mean(dim=-1)\n",
    "    num = int((pred > 0).float().item())\n",
    "    pred = num2tag[num]\n",
    "    return pred, out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can choose a random review and see it's real score and my model's predicted score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love the Twinings Darjeeling Tea.  I have a hard time finding it in the stores, so being able to order it is a<br />real treat.  I have ordered flavors that I have a hard time finding in the stores.  I enjoy curling up with a warm<br />blanket in front of the TV with a good DVD (NCIS)and  a good cup of Twinings Tea!!!!!!!\n",
      "\n",
      "True score: 5\n",
      "Pred score: 5\n"
     ]
    }
   ],
   "source": [
    "# predict with a random item from validation set\n",
    "item = df_val.sample(n=1, random_state=0)\n",
    "text = item['Text'].item()\n",
    "score = item['Score'].item()\n",
    "print(text)\n",
    "print()\n",
    "print(f'True score: {score}')\n",
    "pred,out = predict(text)\n",
    "print(f'Pred score: {pred}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can also see the logit output of the model after each character of the review. High positive numbers mean it is confident the review is 5-star, while low negative numbers mean it is confident the review is 1-star. It's interesting to see what it thinks at different points along its journey through the sequence of characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Char</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>-1.382982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>-0.743601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l</td>\n",
       "      <td>2.843598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>o</td>\n",
       "      <td>0.727741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v</td>\n",
       "      <td>6.607273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>e</td>\n",
       "      <td>14.494108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>9.297186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>t</td>\n",
       "      <td>11.173916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>h</td>\n",
       "      <td>10.580995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>e</td>\n",
       "      <td>16.051893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>10.129072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>T</td>\n",
       "      <td>10.074274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>w</td>\n",
       "      <td>2.789905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>i</td>\n",
       "      <td>3.387840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>n</td>\n",
       "      <td>3.123985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>i</td>\n",
       "      <td>3.369439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>n</td>\n",
       "      <td>2.544080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>g</td>\n",
       "      <td>4.709953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>s</td>\n",
       "      <td>0.576134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td></td>\n",
       "      <td>2.354173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>D</td>\n",
       "      <td>-1.974361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>a</td>\n",
       "      <td>0.625651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>r</td>\n",
       "      <td>-0.343179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>j</td>\n",
       "      <td>0.382724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>e</td>\n",
       "      <td>1.918831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>e</td>\n",
       "      <td>-0.492795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>l</td>\n",
       "      <td>-4.807822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>i</td>\n",
       "      <td>-4.860992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>n</td>\n",
       "      <td>-7.784351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>g</td>\n",
       "      <td>-5.234102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td></td>\n",
       "      <td>-5.281476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>T</td>\n",
       "      <td>-7.541530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>e</td>\n",
       "      <td>-7.175310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>a</td>\n",
       "      <td>-5.364904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>.</td>\n",
       "      <td>-9.352414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td></td>\n",
       "      <td>-8.916161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td></td>\n",
       "      <td>-9.003208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>I</td>\n",
       "      <td>-10.703010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td></td>\n",
       "      <td>-9.212873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>h</td>\n",
       "      <td>-4.030747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>a</td>\n",
       "      <td>-1.434895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>v</td>\n",
       "      <td>1.754737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>e</td>\n",
       "      <td>5.793775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td></td>\n",
       "      <td>0.192133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>a</td>\n",
       "      <td>-0.003633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td></td>\n",
       "      <td>-0.764155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>h</td>\n",
       "      <td>-1.927791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>a</td>\n",
       "      <td>-2.297977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>r</td>\n",
       "      <td>-3.277946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>d</td>\n",
       "      <td>-8.776730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td></td>\n",
       "      <td>-8.263985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>t</td>\n",
       "      <td>-13.923785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>i</td>\n",
       "      <td>-14.397309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>m</td>\n",
       "      <td>-6.863766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>e</td>\n",
       "      <td>-3.001070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td></td>\n",
       "      <td>-3.137481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>f</td>\n",
       "      <td>0.377868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>i</td>\n",
       "      <td>3.561335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>n</td>\n",
       "      <td>5.926256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>d</td>\n",
       "      <td>10.561653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>i</td>\n",
       "      <td>7.683079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>n</td>\n",
       "      <td>6.655920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>g</td>\n",
       "      <td>11.264160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td></td>\n",
       "      <td>11.146191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>i</td>\n",
       "      <td>10.064035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>t</td>\n",
       "      <td>6.367836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td></td>\n",
       "      <td>7.061513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>i</td>\n",
       "      <td>5.369657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>n</td>\n",
       "      <td>4.064440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td></td>\n",
       "      <td>7.151246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>t</td>\n",
       "      <td>4.964516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>h</td>\n",
       "      <td>5.355275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>e</td>\n",
       "      <td>10.474828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td></td>\n",
       "      <td>5.602304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>s</td>\n",
       "      <td>3.759460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>t</td>\n",
       "      <td>3.672830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>o</td>\n",
       "      <td>5.644045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>r</td>\n",
       "      <td>3.554094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>e</td>\n",
       "      <td>11.132253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>s</td>\n",
       "      <td>5.337820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>,</td>\n",
       "      <td>6.336548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td></td>\n",
       "      <td>8.479760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>s</td>\n",
       "      <td>4.251296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>o</td>\n",
       "      <td>4.143676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td></td>\n",
       "      <td>8.752808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>b</td>\n",
       "      <td>2.488508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>e</td>\n",
       "      <td>10.939309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>i</td>\n",
       "      <td>11.471529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>n</td>\n",
       "      <td>12.295936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>g</td>\n",
       "      <td>12.993104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td></td>\n",
       "      <td>11.853109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>a</td>\n",
       "      <td>11.939346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>b</td>\n",
       "      <td>5.339501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>l</td>\n",
       "      <td>8.111081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>e</td>\n",
       "      <td>10.993099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td></td>\n",
       "      <td>6.543501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>t</td>\n",
       "      <td>3.370125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>o</td>\n",
       "      <td>2.290602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td></td>\n",
       "      <td>2.913841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>o</td>\n",
       "      <td>2.062861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>r</td>\n",
       "      <td>0.540694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>d</td>\n",
       "      <td>3.565718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>e</td>\n",
       "      <td>7.594231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>r</td>\n",
       "      <td>1.550394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td></td>\n",
       "      <td>2.530956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>i</td>\n",
       "      <td>1.643165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>t</td>\n",
       "      <td>-3.078263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td></td>\n",
       "      <td>0.620905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>i</td>\n",
       "      <td>-0.550588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>s</td>\n",
       "      <td>-4.110429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td></td>\n",
       "      <td>-0.956298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>a</td>\n",
       "      <td>1.019348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>&lt;</td>\n",
       "      <td>1.398386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>b</td>\n",
       "      <td>0.300186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>r</td>\n",
       "      <td>-0.273109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td></td>\n",
       "      <td>3.379119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>/</td>\n",
       "      <td>3.107277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>&gt;</td>\n",
       "      <td>1.402629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>r</td>\n",
       "      <td>0.404704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>e</td>\n",
       "      <td>6.571111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>a</td>\n",
       "      <td>10.863617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>l</td>\n",
       "      <td>12.252945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td></td>\n",
       "      <td>9.097515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>t</td>\n",
       "      <td>7.926036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>r</td>\n",
       "      <td>3.048945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>e</td>\n",
       "      <td>9.057740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>a</td>\n",
       "      <td>13.353258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>t</td>\n",
       "      <td>13.356881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>.</td>\n",
       "      <td>14.720496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td></td>\n",
       "      <td>16.313036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td></td>\n",
       "      <td>18.629242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>I</td>\n",
       "      <td>21.438156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td></td>\n",
       "      <td>19.020924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>h</td>\n",
       "      <td>20.644032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>a</td>\n",
       "      <td>25.895823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>v</td>\n",
       "      <td>27.611197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>e</td>\n",
       "      <td>28.280695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td></td>\n",
       "      <td>18.999386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>o</td>\n",
       "      <td>15.693285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>r</td>\n",
       "      <td>10.979230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>d</td>\n",
       "      <td>15.136070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>e</td>\n",
       "      <td>18.093708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>r</td>\n",
       "      <td>8.548805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>e</td>\n",
       "      <td>14.887450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>d</td>\n",
       "      <td>11.423765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td></td>\n",
       "      <td>6.580808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>f</td>\n",
       "      <td>5.963354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>l</td>\n",
       "      <td>7.719245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>a</td>\n",
       "      <td>7.434157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>v</td>\n",
       "      <td>6.583745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>o</td>\n",
       "      <td>2.558927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>r</td>\n",
       "      <td>-0.871565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>s</td>\n",
       "      <td>-4.372262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td></td>\n",
       "      <td>-3.177346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>t</td>\n",
       "      <td>-7.652982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>h</td>\n",
       "      <td>-4.211740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>a</td>\n",
       "      <td>-2.830634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>t</td>\n",
       "      <td>-6.570431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td></td>\n",
       "      <td>-3.642743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>I</td>\n",
       "      <td>-3.225590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td></td>\n",
       "      <td>-1.616328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>h</td>\n",
       "      <td>2.020102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>a</td>\n",
       "      <td>4.486978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>v</td>\n",
       "      <td>8.633564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>e</td>\n",
       "      <td>14.856762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td></td>\n",
       "      <td>7.824267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>a</td>\n",
       "      <td>9.345968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td></td>\n",
       "      <td>8.912413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>h</td>\n",
       "      <td>7.603973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>a</td>\n",
       "      <td>9.609535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>r</td>\n",
       "      <td>3.509012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>d</td>\n",
       "      <td>0.541219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td></td>\n",
       "      <td>-1.341775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>t</td>\n",
       "      <td>-5.222660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>i</td>\n",
       "      <td>-5.350745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>m</td>\n",
       "      <td>0.552200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>e</td>\n",
       "      <td>4.667899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td></td>\n",
       "      <td>4.076197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>f</td>\n",
       "      <td>5.004473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>i</td>\n",
       "      <td>7.754672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>n</td>\n",
       "      <td>8.870659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>d</td>\n",
       "      <td>13.243422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>i</td>\n",
       "      <td>9.411191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>n</td>\n",
       "      <td>8.264633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>g</td>\n",
       "      <td>11.883003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td></td>\n",
       "      <td>11.467314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>i</td>\n",
       "      <td>10.175190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>n</td>\n",
       "      <td>8.163160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td></td>\n",
       "      <td>8.879582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>t</td>\n",
       "      <td>6.038376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>h</td>\n",
       "      <td>6.171897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>e</td>\n",
       "      <td>10.520493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td></td>\n",
       "      <td>5.196708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>s</td>\n",
       "      <td>3.819716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>t</td>\n",
       "      <td>2.981976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>o</td>\n",
       "      <td>5.002976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>r</td>\n",
       "      <td>3.192623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>e</td>\n",
       "      <td>10.255739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>s</td>\n",
       "      <td>4.678390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>.</td>\n",
       "      <td>5.431715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td></td>\n",
       "      <td>6.413316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td></td>\n",
       "      <td>8.994007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>I</td>\n",
       "      <td>8.656418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td></td>\n",
       "      <td>7.575546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>e</td>\n",
       "      <td>14.646093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>n</td>\n",
       "      <td>10.446152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>j</td>\n",
       "      <td>8.904631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>o</td>\n",
       "      <td>10.099805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>y</td>\n",
       "      <td>17.249233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td></td>\n",
       "      <td>17.511072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>c</td>\n",
       "      <td>22.370003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>u</td>\n",
       "      <td>16.085022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>r</td>\n",
       "      <td>11.618093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>l</td>\n",
       "      <td>18.798183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>i</td>\n",
       "      <td>18.923450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>n</td>\n",
       "      <td>18.786377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>g</td>\n",
       "      <td>16.463491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td></td>\n",
       "      <td>14.965424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>u</td>\n",
       "      <td>10.517687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>p</td>\n",
       "      <td>9.851725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td></td>\n",
       "      <td>12.272393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>w</td>\n",
       "      <td>7.045405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>i</td>\n",
       "      <td>10.894455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>t</td>\n",
       "      <td>10.960005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>h</td>\n",
       "      <td>14.136219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td></td>\n",
       "      <td>14.939959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>a</td>\n",
       "      <td>18.936104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td></td>\n",
       "      <td>17.204601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>w</td>\n",
       "      <td>10.315834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>a</td>\n",
       "      <td>13.519276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>r</td>\n",
       "      <td>7.064391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>m</td>\n",
       "      <td>8.440736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>&lt;</td>\n",
       "      <td>7.197323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>b</td>\n",
       "      <td>5.058152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>r</td>\n",
       "      <td>3.283810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td></td>\n",
       "      <td>6.970561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>/</td>\n",
       "      <td>4.527203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>&gt;</td>\n",
       "      <td>3.179486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>b</td>\n",
       "      <td>1.493254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>l</td>\n",
       "      <td>2.965573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>a</td>\n",
       "      <td>3.199889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>n</td>\n",
       "      <td>2.940604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>k</td>\n",
       "      <td>2.951792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>e</td>\n",
       "      <td>8.922749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>t</td>\n",
       "      <td>5.138910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td></td>\n",
       "      <td>3.490263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>i</td>\n",
       "      <td>1.108750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>n</td>\n",
       "      <td>0.238054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td></td>\n",
       "      <td>1.492292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>f</td>\n",
       "      <td>2.281016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>r</td>\n",
       "      <td>0.897430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>o</td>\n",
       "      <td>-1.288631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>n</td>\n",
       "      <td>0.901090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>t</td>\n",
       "      <td>-2.347231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td></td>\n",
       "      <td>-1.208503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>o</td>\n",
       "      <td>-3.584937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>f</td>\n",
       "      <td>-0.233031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td></td>\n",
       "      <td>-1.409594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>t</td>\n",
       "      <td>-8.165470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>h</td>\n",
       "      <td>-6.821725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>e</td>\n",
       "      <td>-4.549570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td></td>\n",
       "      <td>-6.012465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>T</td>\n",
       "      <td>-7.840746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>V</td>\n",
       "      <td>-6.358616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td></td>\n",
       "      <td>-6.056773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>w</td>\n",
       "      <td>-9.583223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>i</td>\n",
       "      <td>-9.031116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>t</td>\n",
       "      <td>-11.676027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>h</td>\n",
       "      <td>-6.962907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td></td>\n",
       "      <td>-3.207897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>a</td>\n",
       "      <td>-0.627246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td></td>\n",
       "      <td>2.015455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>g</td>\n",
       "      <td>5.727909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>o</td>\n",
       "      <td>5.605223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>o</td>\n",
       "      <td>6.805303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>d</td>\n",
       "      <td>13.747595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td></td>\n",
       "      <td>13.850526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>D</td>\n",
       "      <td>9.751068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>V</td>\n",
       "      <td>10.282175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>D</td>\n",
       "      <td>5.375936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td></td>\n",
       "      <td>5.155995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>(</td>\n",
       "      <td>2.235314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>N</td>\n",
       "      <td>-1.280478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>C</td>\n",
       "      <td>-2.170512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>I</td>\n",
       "      <td>-3.536944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>S</td>\n",
       "      <td>-2.898583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>)</td>\n",
       "      <td>-0.302366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>a</td>\n",
       "      <td>2.284047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>n</td>\n",
       "      <td>3.282784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>d</td>\n",
       "      <td>4.069178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td></td>\n",
       "      <td>1.521930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td></td>\n",
       "      <td>2.113746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>a</td>\n",
       "      <td>3.034526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td></td>\n",
       "      <td>4.185455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>g</td>\n",
       "      <td>6.174810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>o</td>\n",
       "      <td>4.868377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>o</td>\n",
       "      <td>6.617839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>d</td>\n",
       "      <td>14.781691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td></td>\n",
       "      <td>13.952618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>c</td>\n",
       "      <td>19.927326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>u</td>\n",
       "      <td>14.291655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>p</td>\n",
       "      <td>13.924896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td></td>\n",
       "      <td>14.960656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>o</td>\n",
       "      <td>11.765359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>f</td>\n",
       "      <td>11.945626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td></td>\n",
       "      <td>10.795568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>T</td>\n",
       "      <td>7.744024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>w</td>\n",
       "      <td>0.755233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>i</td>\n",
       "      <td>1.168773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>n</td>\n",
       "      <td>2.276191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>i</td>\n",
       "      <td>2.215481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>n</td>\n",
       "      <td>2.678650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>g</td>\n",
       "      <td>3.464680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>s</td>\n",
       "      <td>-1.103469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td></td>\n",
       "      <td>1.107978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>T</td>\n",
       "      <td>-0.457986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>e</td>\n",
       "      <td>2.302411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>a</td>\n",
       "      <td>4.336285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>!</td>\n",
       "      <td>4.801852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>!</td>\n",
       "      <td>6.024553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>!</td>\n",
       "      <td>5.836412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>!</td>\n",
       "      <td>4.336611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>!</td>\n",
       "      <td>2.124870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>!</td>\n",
       "      <td>-0.345800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>!</td>\n",
       "      <td>-2.690798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Char       Pred\n",
       "0      I  -1.382982\n",
       "1         -0.743601\n",
       "2      l   2.843598\n",
       "3      o   0.727741\n",
       "4      v   6.607273\n",
       "5      e  14.494108\n",
       "6          9.297186\n",
       "7      t  11.173916\n",
       "8      h  10.580995\n",
       "9      e  16.051893\n",
       "10        10.129072\n",
       "11     T  10.074274\n",
       "12     w   2.789905\n",
       "13     i   3.387840\n",
       "14     n   3.123985\n",
       "15     i   3.369439\n",
       "16     n   2.544080\n",
       "17     g   4.709953\n",
       "18     s   0.576134\n",
       "19         2.354173\n",
       "20     D  -1.974361\n",
       "21     a   0.625651\n",
       "22     r  -0.343179\n",
       "23     j   0.382724\n",
       "24     e   1.918831\n",
       "25     e  -0.492795\n",
       "26     l  -4.807822\n",
       "27     i  -4.860992\n",
       "28     n  -7.784351\n",
       "29     g  -5.234102\n",
       "30        -5.281476\n",
       "31     T  -7.541530\n",
       "32     e  -7.175310\n",
       "33     a  -5.364904\n",
       "34     .  -9.352414\n",
       "35        -8.916161\n",
       "36        -9.003208\n",
       "37     I -10.703010\n",
       "38        -9.212873\n",
       "39     h  -4.030747\n",
       "40     a  -1.434895\n",
       "41     v   1.754737\n",
       "42     e   5.793775\n",
       "43         0.192133\n",
       "44     a  -0.003633\n",
       "45        -0.764155\n",
       "46     h  -1.927791\n",
       "47     a  -2.297977\n",
       "48     r  -3.277946\n",
       "49     d  -8.776730\n",
       "50        -8.263985\n",
       "51     t -13.923785\n",
       "52     i -14.397309\n",
       "53     m  -6.863766\n",
       "54     e  -3.001070\n",
       "55        -3.137481\n",
       "56     f   0.377868\n",
       "57     i   3.561335\n",
       "58     n   5.926256\n",
       "59     d  10.561653\n",
       "60     i   7.683079\n",
       "61     n   6.655920\n",
       "62     g  11.264160\n",
       "63        11.146191\n",
       "64     i  10.064035\n",
       "65     t   6.367836\n",
       "66         7.061513\n",
       "67     i   5.369657\n",
       "68     n   4.064440\n",
       "69         7.151246\n",
       "70     t   4.964516\n",
       "71     h   5.355275\n",
       "72     e  10.474828\n",
       "73         5.602304\n",
       "74     s   3.759460\n",
       "75     t   3.672830\n",
       "76     o   5.644045\n",
       "77     r   3.554094\n",
       "78     e  11.132253\n",
       "79     s   5.337820\n",
       "80     ,   6.336548\n",
       "81         8.479760\n",
       "82     s   4.251296\n",
       "83     o   4.143676\n",
       "84         8.752808\n",
       "85     b   2.488508\n",
       "86     e  10.939309\n",
       "87     i  11.471529\n",
       "88     n  12.295936\n",
       "89     g  12.993104\n",
       "90        11.853109\n",
       "91     a  11.939346\n",
       "92     b   5.339501\n",
       "93     l   8.111081\n",
       "94     e  10.993099\n",
       "95         6.543501\n",
       "96     t   3.370125\n",
       "97     o   2.290602\n",
       "98         2.913841\n",
       "99     o   2.062861\n",
       "100    r   0.540694\n",
       "101    d   3.565718\n",
       "102    e   7.594231\n",
       "103    r   1.550394\n",
       "104        2.530956\n",
       "105    i   1.643165\n",
       "106    t  -3.078263\n",
       "107        0.620905\n",
       "108    i  -0.550588\n",
       "109    s  -4.110429\n",
       "110       -0.956298\n",
       "111    a   1.019348\n",
       "112    <   1.398386\n",
       "113    b   0.300186\n",
       "114    r  -0.273109\n",
       "115        3.379119\n",
       "116    /   3.107277\n",
       "117    >   1.402629\n",
       "118    r   0.404704\n",
       "119    e   6.571111\n",
       "120    a  10.863617\n",
       "121    l  12.252945\n",
       "122        9.097515\n",
       "123    t   7.926036\n",
       "124    r   3.048945\n",
       "125    e   9.057740\n",
       "126    a  13.353258\n",
       "127    t  13.356881\n",
       "128    .  14.720496\n",
       "129       16.313036\n",
       "130       18.629242\n",
       "131    I  21.438156\n",
       "132       19.020924\n",
       "133    h  20.644032\n",
       "134    a  25.895823\n",
       "135    v  27.611197\n",
       "136    e  28.280695\n",
       "137       18.999386\n",
       "138    o  15.693285\n",
       "139    r  10.979230\n",
       "140    d  15.136070\n",
       "141    e  18.093708\n",
       "142    r   8.548805\n",
       "143    e  14.887450\n",
       "144    d  11.423765\n",
       "145        6.580808\n",
       "146    f   5.963354\n",
       "147    l   7.719245\n",
       "148    a   7.434157\n",
       "149    v   6.583745\n",
       "150    o   2.558927\n",
       "151    r  -0.871565\n",
       "152    s  -4.372262\n",
       "153       -3.177346\n",
       "154    t  -7.652982\n",
       "155    h  -4.211740\n",
       "156    a  -2.830634\n",
       "157    t  -6.570431\n",
       "158       -3.642743\n",
       "159    I  -3.225590\n",
       "160       -1.616328\n",
       "161    h   2.020102\n",
       "162    a   4.486978\n",
       "163    v   8.633564\n",
       "164    e  14.856762\n",
       "165        7.824267\n",
       "166    a   9.345968\n",
       "167        8.912413\n",
       "168    h   7.603973\n",
       "169    a   9.609535\n",
       "170    r   3.509012\n",
       "171    d   0.541219\n",
       "172       -1.341775\n",
       "173    t  -5.222660\n",
       "174    i  -5.350745\n",
       "175    m   0.552200\n",
       "176    e   4.667899\n",
       "177        4.076197\n",
       "178    f   5.004473\n",
       "179    i   7.754672\n",
       "180    n   8.870659\n",
       "181    d  13.243422\n",
       "182    i   9.411191\n",
       "183    n   8.264633\n",
       "184    g  11.883003\n",
       "185       11.467314\n",
       "186    i  10.175190\n",
       "187    n   8.163160\n",
       "188        8.879582\n",
       "189    t   6.038376\n",
       "190    h   6.171897\n",
       "191    e  10.520493\n",
       "192        5.196708\n",
       "193    s   3.819716\n",
       "194    t   2.981976\n",
       "195    o   5.002976\n",
       "196    r   3.192623\n",
       "197    e  10.255739\n",
       "198    s   4.678390\n",
       "199    .   5.431715\n",
       "200        6.413316\n",
       "201        8.994007\n",
       "202    I   8.656418\n",
       "203        7.575546\n",
       "204    e  14.646093\n",
       "205    n  10.446152\n",
       "206    j   8.904631\n",
       "207    o  10.099805\n",
       "208    y  17.249233\n",
       "209       17.511072\n",
       "210    c  22.370003\n",
       "211    u  16.085022\n",
       "212    r  11.618093\n",
       "213    l  18.798183\n",
       "214    i  18.923450\n",
       "215    n  18.786377\n",
       "216    g  16.463491\n",
       "217       14.965424\n",
       "218    u  10.517687\n",
       "219    p   9.851725\n",
       "220       12.272393\n",
       "221    w   7.045405\n",
       "222    i  10.894455\n",
       "223    t  10.960005\n",
       "224    h  14.136219\n",
       "225       14.939959\n",
       "226    a  18.936104\n",
       "227       17.204601\n",
       "228    w  10.315834\n",
       "229    a  13.519276\n",
       "230    r   7.064391\n",
       "231    m   8.440736\n",
       "232    <   7.197323\n",
       "233    b   5.058152\n",
       "234    r   3.283810\n",
       "235        6.970561\n",
       "236    /   4.527203\n",
       "237    >   3.179486\n",
       "238    b   1.493254\n",
       "239    l   2.965573\n",
       "240    a   3.199889\n",
       "241    n   2.940604\n",
       "242    k   2.951792\n",
       "243    e   8.922749\n",
       "244    t   5.138910\n",
       "245        3.490263\n",
       "246    i   1.108750\n",
       "247    n   0.238054\n",
       "248        1.492292\n",
       "249    f   2.281016\n",
       "250    r   0.897430\n",
       "251    o  -1.288631\n",
       "252    n   0.901090\n",
       "253    t  -2.347231\n",
       "254       -1.208503\n",
       "255    o  -3.584937\n",
       "256    f  -0.233031\n",
       "257       -1.409594\n",
       "258    t  -8.165470\n",
       "259    h  -6.821725\n",
       "260    e  -4.549570\n",
       "261       -6.012465\n",
       "262    T  -7.840746\n",
       "263    V  -6.358616\n",
       "264       -6.056773\n",
       "265    w  -9.583223\n",
       "266    i  -9.031116\n",
       "267    t -11.676027\n",
       "268    h  -6.962907\n",
       "269       -3.207897\n",
       "270    a  -0.627246\n",
       "271        2.015455\n",
       "272    g   5.727909\n",
       "273    o   5.605223\n",
       "274    o   6.805303\n",
       "275    d  13.747595\n",
       "276       13.850526\n",
       "277    D   9.751068\n",
       "278    V  10.282175\n",
       "279    D   5.375936\n",
       "280        5.155995\n",
       "281    (   2.235314\n",
       "282    N  -1.280478\n",
       "283    C  -2.170512\n",
       "284    I  -3.536944\n",
       "285    S  -2.898583\n",
       "286    )  -0.302366\n",
       "287    a   2.284047\n",
       "288    n   3.282784\n",
       "289    d   4.069178\n",
       "290        1.521930\n",
       "291        2.113746\n",
       "292    a   3.034526\n",
       "293        4.185455\n",
       "294    g   6.174810\n",
       "295    o   4.868377\n",
       "296    o   6.617839\n",
       "297    d  14.781691\n",
       "298       13.952618\n",
       "299    c  19.927326\n",
       "300    u  14.291655\n",
       "301    p  13.924896\n",
       "302       14.960656\n",
       "303    o  11.765359\n",
       "304    f  11.945626\n",
       "305       10.795568\n",
       "306    T   7.744024\n",
       "307    w   0.755233\n",
       "308    i   1.168773\n",
       "309    n   2.276191\n",
       "310    i   2.215481\n",
       "311    n   2.678650\n",
       "312    g   3.464680\n",
       "313    s  -1.103469\n",
       "314        1.107978\n",
       "315    T  -0.457986\n",
       "316    e   2.302411\n",
       "317    a   4.336285\n",
       "318    !   4.801852\n",
       "319    !   6.024553\n",
       "320    !   5.836412\n",
       "321    !   4.336611\n",
       "322    !   2.124870\n",
       "323    !  -0.345800\n",
       "324    !  -2.690798"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show prediction after each character\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.DataFrame({\"Char\":list(text), \"Pred\":out.numpy()})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
